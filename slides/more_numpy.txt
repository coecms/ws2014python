Performance NumPy
=================

The Zen of NumPy

* Data arrays are better than objects.

* Contiguous is better than strided.

* Strided is better than scattered.

* Broadcasting is always a good idea.

* Vectorization is better than looping...

* ... unless it's too complicated; go compile!

(Paraphrased from Travis Oliphant)


Array structure
===============

.. code:: python

   x = np.arange(24).reshape(2, 3, 4)

What do these tell us?

============== ==================
``x.size``     ``24``
``x.shape``    ``(2, 3, 4)``
``x.dtype``    ``dtype('int64')``
``x.itemsize`` ``8``
``x.nbytes``   ``192``
``x.strides``  ``(96, 32, 8)``
============== ==================


Inside the array
================

Look at the data:

.. code:: python

   x = np.array([[1, 2, 3], [4, 5, 6]],
                dtype=np.int8)

Data of any shape is always a sequence:

+----+----+----+----+----+----+
|0x01|0x02|0x03|0x04|0x05|0x06|
+----+----+----+----+----+----+

CPUs work most efficiently along this "vector".


NumPy memory order
==================

Row-major ("C") vs column-major ("Fortran")

.. code:: python

   x = np.array([[1, 2, 3], [4, 5, 6]],
                dtype=np.uint8, order='C')

+----+----+----+----+----+----+
|0x01|0x02|0x03|0x04|0x05|0x06|
+----+----+----+----+----+----+

.. code:: python

   y = np.array([[1, 2, 3], [4, 5, 6]],
                dtype=np.uint8, order='F')

+----+----+----+----+----+----+
|0x01|0x04|0x02|0x05|0x03|0x06|
+----+----+----+----+----+----+


Quiz
====

1. Which is faster?

   * ``np.arange(1e4).sum()``

   * ``np.arange(8e4)[::8].sum()?``

2. Which is faster?

   * ``np.arange(1e4).sum()``

   * ``np.arange(1e4)[::-1].sum()``

3. If ``x.shape`` is ``(10, 10)``, which is contiguous?

   * ``x[:, 3:7]``

   * ``x[3:7, :]``


"Fast" indexing
===============

How do we index something like :math:`u(x, y, z, t)`?

Row-major (``order='C'``):

.. code:: python

   x = np.empty(n_t, n_z, n_y, n_x)

Column-major (``order='F'``):

.. code:: python

   x = np.empty(n_x, n_y, n_z, n_t)

Which variable is contiguous? Which is least so?


Memory Usage
============

How much memory does this use?

.. code:: python

   x = np.empty(N, ...)
   for i in range(N):
      y = f(...)
      x[i] = y


Memory Usage
============

Mem usage: ``x.nbytes + 2 * y.nbytes``

.. code:: python

   x = np.empty(N, ...)
   for i in range(N):
      y = f(...)
      x[i] = y
      del y

``y`` is bound to ``f``, so it's saved until next ``f`` is done.

Use ``del y`` to release early.


Copying Arrays
==============

.. code:: python

   x = np.arange(10)
   y = x
   z = x[:]

What happens to ``y`` and ``z`` under these two operations?

.. code:: python

   x.shape(2,5)
   x[0] = 999.

What does ``x.flags`` say?


How to copy, *really* copy
==========================

Invoke the ``copy`` command:

.. code:: python

   yy = x.copy()

Or pre-allocate and copy the values:

.. code:: python

   zz = np.empty_like(x)
   zz[:] = x


Broadcasting
============

This won't work; outer dimensions don't match

.. code:: python

   x = np.arange(12).reshape(3, 4)
   y = np.arange(12).reshape(4, 3)
   x * y

But this works fine:

.. code:: python

   x = np.arange(12).reshape(3, 4)
   y = np.arange(4)
   x * y


Broadcasting Rules
==================

Outer axes are *broadcast* to inner axes

This is an explicit ``(N,)`` to ``(M, N)`` broadcast:

.. code:: python

   x = np.empty((3,4))
   x[:] = np.arange(4)

This is an implicit ``(1,)`` to ``(N,)`` broadcast:

.. code:: python

   x = np.empty(100)
   x[:] = 5.


Extending dimensions
====================

What if you want to broadcast an inner dimension? Use ``newaxis``:

.. code:: python

   x = np.arange(12).reshape(3, 4)
   y = np.arange(3)

   x * y[:, np.newaxis]

This is another implicit broadcast.


Implicit indexing
=================

You can omit all inner indices with ``...``:

.. code:: python

   x = np.arange(24).reshape(2, 3, 4)

The following two assignments are equivalent:

.. code:: python

   x[:, :, :, 2, 3] = 0.
   x[..., 2, 3] = 0.

Useful when looping over arrays of different shapes.


Exercise
========

Calculate :math:`\tfrac{d}{dx} \sin x` on :math:`[0, 10)` using a forward
difference:

.. math:: \frac{d}{dx} \left(\sin x \right)
            \approx \frac{\sin (x + h) - \sin x}{h}

Use :math:`h = 0.1`


Solution
========

.. code:: python

   x = np.arange(0., 10., 0.1)
   h = x[1:] - x[:-1]

   d_sin = (np.sin(x[1:]) - np.sin(x[:-1])) / h

or just

.. code:: python

   d_sin = np.diff(sin(x)) / np.diff(x)


Exercise
========

Given two random 2D arrays:

.. code:: python

   x = np.random.rand(2, 5)
   y = np.random.rand(3, 5)

vectorise this sum along the tail axis:

.. math:: S_{ij} = \sum_{k} x_{ik} y_{jk}


Solution
========

Two solutions here, one using ``newaxis``:

.. code:: python

   S = (x[:, np.newaxis, :] * y[np.newaxis, :, :]
        ).sum(axis=-1)

Another uses the ``einsum`` function:

.. code:: python

   S = np.einsum('ik,jk->ij', x, y)


Exercise
========

For this random matrix:

.. code:: python

   N_t, N_y, N_x = 50, 37, 73
   x = np.random.randn(N_t, N_y, N_x)

average over the outer axes (``x``, ``y``) to construct a time series,
``x_mean``


Solution
========

One solution is to unravel the outer axes:

.. code:: python

   x_mean = x.reshape(N_t, -1).mean(axis=-1)

or set a multidimensional axis:

.. code:: python

   x_mean = x.mean(axis=(1, 2))

or take the functional approach:

.. code:: python

   x_mean = np.apply_over_axes(np.sum, x, (1, 2))


Fancy Indexing
==============

Arrays can be access by integers (and slices):

.. code:: python

   >> x = np.arange(10)**2
   >> x[4]
   16

but also by index arrays:

.. code:: python

   >> idx = [1, 4, 7, 9, 2]
   >> x[idx]
   array([1, 16, 49, 81, 4])


Multidim index arrays
=====================

Using index arrays preserves their shape:

.. code:: python

   >> x = np.arange(10)**2
   >> idx = np.array([[2, 3], [4, 5]])
   >> x[idx]
   array([[ 4,  9],
          [16, 25]])

Note that the original shape of ``x`` is lost.

Multidimensional index arrays must be ``ndarray``\ s.


Indexing multidim arrays
========================

Things get tricky with multidimensional arrays. Take this:

.. code:: python

   x = (np.arange(12)**2).reshape(3, 4)

What does ``x[idx]`` give for these cases?

1. .. code:: python

      idx = np.array([2, 0, 1])

2. .. code:: python

      idx = np.array([[0, 1], [1, 2]])


Solution
========

1. .. code:: python

      array([[ 64,  81, 100, 121],
             [  0,   1,   4,   9],
             [ 16,  25,  36,  49]])

   Each index ``i`` is replaced by row ``x[i]``

2. .. code:: python

      array([[[  0,   1,   4,   9],
              [ 16,  25,  36,  49]],
             [[ 16,  25,  36,  49],
              [ 64,  81, 100, 121]]])

   Each index ``k = idx[i, j]`` is replaced with ``x[k]``.


Multidim indexing
=================

So how do we get ``x[2, 3]`` in an index array?

Use a list of index arrays:

.. code:: python

   >> x = (np.arange(12)**2).reshape(3, 4)
   >> idx = [np.array([0, 1, 2]),
             np.array([1, 2, 3])]
   >> x[idx]
   array([  1,  36, 121])


Index grid generation
=====================

Two useful functions for generating index arrays

.. code:: python

   >> np.mgrid[:2,:3]
   array([ [[0, 0, 0],
            [1, 1, 1]],
           [[0, 1, 2],
            [0, 1, 2]] ])

   >> np.ogrid[:2,:3]
   [ array([[0],  ,  array([[0, 1, 2]]) ]
            [1]])


Exercise
========

For these arrays:

.. code:: python

   x = np.random.randn(4, 5, 6)
   idx = np.random.randint(0, 2, (5, 6))

How do I vectorise this loop?

.. code:: python

   for j in range(6):
      for i in range(5):
         y[j, i] = x[idx[j, i], j, i]


Solution
========

Use ``mgrid`` (or ``ogrid``) and fancy indexing:

.. code:: python

   J, I = np.mgrid[:5, :6]
   y = x[[idx, J, I]]

List brackets can also be implicit:

.. code:: python

   y = x[idx, J, I]

(``ogrid`` broadcasts to ``mgrid``)


Boolean index arrays
====================

These are similar to index arrays (and easier to use)

To replace negative values of an array to zero:

.. code:: python

   x = np.random.randn(10, 10)
   x[x < 0] = 0.

If you prefer index arrays, use ``nonzero``:

.. code:: python

   idx = np.nonzero(x < 0)


Masked Arrays
=============

Use masks to carry a criterion across operations:

.. code:: python

   x = np.random.randn(3, 4)
   x_m = np.ma.masked_array(x, x > 0.)

Masked arrays can be very convenient, but be prepared to handle occasional
bugs.


Summary
=======

* Contiguous vs. strided vs. scattered

* Views vs. copies

* Broadcasting (and ``newaxis``) rules

* Index arrays
